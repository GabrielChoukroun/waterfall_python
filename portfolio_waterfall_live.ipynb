{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e69b4082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import openpyxl\n",
    "from datetime import datetime\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdb11193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You need coin recon sheet plus the APY/COFA sheet for live waterfall\n",
    "# I download the sheets and save them as excel files so I have a copy of the raw data (for debugging and archiving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a63816f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def melt(df, col_vals, key, value):\n",
    "    # melt pandas dataframe\n",
    "    # col_vars: list of the columns that will be melted\n",
    "    # key: name of column needs to be generated\n",
    "    # value: name of the column that contains the value of interest\n",
    "    keep_vars = df.columns.difference(col_vals)\n",
    "    melted = []\n",
    "    for c in col_vals:\n",
    "        melted_c = df[keep_vars].copy()\n",
    "        melted_c[key] = c\n",
    "        melted_c[value] = df[c]\n",
    "        melted.append(melted_c)\n",
    "    return pd.concat(melted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# CHECK IF THE FREEZE IS UPDATED\n",
    "waterfall_freeze = pd.read_excel(\"excel_input/freeze_address.xlsx\", sheet_name='Past Waterfall Freezes')\n",
    "waterfall_freeze.columns = waterfall_freeze.iloc[0]\n",
    "waterfall_freeze.drop([0], inplace = True)\n",
    "wfreeze_last_date = str(waterfall_freeze.iloc[-1][\"Date\"])\n",
    "\n",
    "freeze = pd.read_excel(\"excel_input/freeze_address.xlsx\")\n",
    "freeze.columns = freeze.iloc[0]\n",
    "freeze.drop([0], inplace = True)\n",
    "freeze_last_date = str(freeze.iloc[-1][\"Date\"])\n",
    "\n",
    "isFreeze = wfreeze_last_date != freeze_last_date"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eaddfe03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0          Coin  Bank - Balances  Celsius Network Limited (UK)  \\\n0          Coin  Bank - Balances  Celsius Network Limited (UK)   \n1      Category       undeployed                    undeployed   \n2          Tier              1.0                           1.0   \n3       Default              0.0                           0.0   \n4    wBTC (Y/N)                N                             N   \n..          ...              ...                           ...   \n116  yveCRV-DAO              NaN                           NaN   \n117         ZEC              NaN                           NaN   \n118         ZRX              NaN                           NaN   \n119        ZUSD              NaN                           NaN   \n121       check                1                           0.0   \n\n0    Celsius Network LLC (US)  Celsius Network EU UAB (LT)  \\\n0    Celsius Network LLC (US)  Celsius Network EU UAB (LT)   \n1                  undeployed                   undeployed   \n2                         1.0                          1.0   \n3                         0.0                          0.0   \n4                           N                          NaN   \n..                        ...                          ...   \n116                       NaN                          NaN   \n117                       NaN                          NaN   \n118                       NaN                          NaN   \n119                       NaN                          NaN   \n121                       0.0                          NaN   \n\n0    Celsius Network Finance  Celsius OTC  CEL Treasury  CEL Users  \\\n0    Celsius Network Finance  Celsius OTC  CEL Treasury  CEL Users   \n1                 undeployed   undeployed  CEL Treasury  CEL Users   \n2                        1.0          1.0           1.0        1.0   \n3                        0.0          0.0           0.0        0.0   \n4                          N            N             N          N   \n..                       ...          ...           ...        ...   \n116                      NaN          NaN           NaN        NaN   \n117                      NaN          NaN           NaN        NaN   \n118                      NaN          NaN           NaN        NaN   \n119                      NaN          NaN           NaN        NaN   \n121                      0.0          0.0           0.0        0.0   \n\n0              Loans Out  ...  DD - CONVEX - gUSD  DD - CONVEX - RAI  \\\n0              Loans Out  ...  DD - CONVEX - gUSD  DD - CONVEX - RAI   \n1    Institutional Loans  ...                defi               defi   \n2                    4.0  ...                 1.0                2.0   \n3                    NaN  ...                 0.0                0.0   \n4                      N  ...                   N                  N   \n..                   ...  ...                 ...                ...   \n116                  NaN  ...                 NaN                NaN   \n117              0.03567  ...                 NaN                NaN   \n118             0.055714  ...                 NaN                NaN   \n119                       ...                 NaN                NaN   \n121                   45  ...                   9                  8   \n\n0    DD - Spartan Token  DD - Banker Joe - LINK.e  DD - Alpha HomoraV2 - AVAX  \\\n0    DD - Spartan Token  DD - Banker Joe - LINK.e  DD - Alpha HomoraV2 - AVAX   \n1                  defi                      defi                        defi   \n2                   2.0                       2.0                         2.0   \n3                   0.0                       0.0                         0.0   \n4                     N                         N                           N   \n..                  ...                       ...                         ...   \n116                 NaN                       NaN                         NaN   \n117                 NaN                       NaN                         NaN   \n118                 NaN                       NaN                         NaN   \n119                 NaN                       NaN                         NaN   \n121                   1                       2.0                         2.0   \n\n0    DeFi-Earmarked  DD - Banker Joe - WBTC.e  DD - Aave - Matic  \\\n0    DeFi-Earmarked  DD - Banker Joe - WBTC.e  DD - Aave - Matic   \n1              defi                      defi               defi   \n2               1.0                       2.0                2.0   \n3               0.0                       0.0                0.0   \n4                 Y                         Y                  N   \n..              ...                       ...                ...   \n116             NaN                       NaN                NaN   \n117             NaN                       NaN                NaN   \n118             NaN                       NaN                NaN   \n119             NaN                       NaN                NaN   \n121               3                         3                  1   \n\n0    DD - Bancor - LINK  DD - Badger - wibBTC  \n0    DD - Bancor - LINK  DD - Badger - wibBTC  \n1                  defi                  defi  \n2                   2.0                   2.0  \n3                   0.0                   0.0  \n4                     N                     Y  \n..                  ...                   ...  \n116                 NaN                   NaN  \n117                 NaN                   NaN  \n118                 NaN                   NaN  \n119                 NaN                   NaN  \n121                 2.0                     3  \n\n[121 rows x 184 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Coin</th>\n      <th>Bank - Balances</th>\n      <th>Celsius Network Limited (UK)</th>\n      <th>Celsius Network LLC (US)</th>\n      <th>Celsius Network EU UAB (LT)</th>\n      <th>Celsius Network Finance</th>\n      <th>Celsius OTC</th>\n      <th>CEL Treasury</th>\n      <th>CEL Users</th>\n      <th>Loans Out</th>\n      <th>...</th>\n      <th>DD - CONVEX - gUSD</th>\n      <th>DD - CONVEX - RAI</th>\n      <th>DD - Spartan Token</th>\n      <th>DD - Banker Joe - LINK.e</th>\n      <th>DD - Alpha HomoraV2 - AVAX</th>\n      <th>DeFi-Earmarked</th>\n      <th>DD - Banker Joe - WBTC.e</th>\n      <th>DD - Aave - Matic</th>\n      <th>DD - Bancor - LINK</th>\n      <th>DD - Badger - wibBTC</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Coin</td>\n      <td>Bank - Balances</td>\n      <td>Celsius Network Limited (UK)</td>\n      <td>Celsius Network LLC (US)</td>\n      <td>Celsius Network EU UAB (LT)</td>\n      <td>Celsius Network Finance</td>\n      <td>Celsius OTC</td>\n      <td>CEL Treasury</td>\n      <td>CEL Users</td>\n      <td>Loans Out</td>\n      <td>...</td>\n      <td>DD - CONVEX - gUSD</td>\n      <td>DD - CONVEX - RAI</td>\n      <td>DD - Spartan Token</td>\n      <td>DD - Banker Joe - LINK.e</td>\n      <td>DD - Alpha HomoraV2 - AVAX</td>\n      <td>DeFi-Earmarked</td>\n      <td>DD - Banker Joe - WBTC.e</td>\n      <td>DD - Aave - Matic</td>\n      <td>DD - Bancor - LINK</td>\n      <td>DD - Badger - wibBTC</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Category</td>\n      <td>undeployed</td>\n      <td>undeployed</td>\n      <td>undeployed</td>\n      <td>undeployed</td>\n      <td>undeployed</td>\n      <td>undeployed</td>\n      <td>CEL Treasury</td>\n      <td>CEL Users</td>\n      <td>Institutional Loans</td>\n      <td>...</td>\n      <td>defi</td>\n      <td>defi</td>\n      <td>defi</td>\n      <td>defi</td>\n      <td>defi</td>\n      <td>defi</td>\n      <td>defi</td>\n      <td>defi</td>\n      <td>defi</td>\n      <td>defi</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Tier</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Default</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>wBTC (Y/N)</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>NaN</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>...</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>Y</td>\n      <td>N</td>\n      <td>N</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>116</th>\n      <td>yveCRV-DAO</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>117</th>\n      <td>ZEC</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.03567</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>118</th>\n      <td>ZRX</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.055714</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>119</th>\n      <td>ZUSD</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td></td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>121</th>\n      <td>check</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>45</td>\n      <td>...</td>\n      <td>9</td>\n      <td>8</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>121 rows × 184 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the raw spreadsheet, downloanded from shared drive\n",
    "#if isFreeze:\n",
    "#    c_recon = pd.ExcelFile(\"excel_input/freeze.xlsx\")\n",
    "#else:\n",
    "#    c_recon = pd.ExcelFile(\"excel_input/Celsius_Reconciliation_Master.xlsx\")\n",
    "c_recon = pd.ExcelFile(\"excel_input/Celsius_Reconciliation_Master.xlsx\")\n",
    "#c_recon = pd.ExcelFile(\"excel_input/freeze.xlsx\")\n",
    "stats = pd.read_excel(c_recon, \"Coin Stats\", header = None)\n",
    "defi = pd.read_excel(c_recon, \"DeFi Assets\")\n",
    "ftx = pd.read_excel(c_recon, \"FTX Summary\")\n",
    "defi_main = pd.read_excel(c_recon, \"DeFi Main\")\n",
    "template = pd.read_excel(\"excel_input/coin_apy_template.xlsx\", \n",
    "                         sheet_name = \"APY\", \n",
    "                         header = None)\n",
    "carry = pd.read_excel(\"excel_input/coin_apy_template.xlsx\", sheet_name='Carry')\n",
    "manual_adjustements = pd.read_excel(\"excel_input/coin_apy_template.xlsx\", \n",
    "                         sheet_name = \"Manual_Adjustments\")\n",
    "\n",
    "deployable = pd.read_excel(\"excel_input/deployable_metric.xlsx\",\n",
    "                           sheet_name=\"Undeployed & Underdeployed\")\n",
    "template.columns = template.iloc[0]\n",
    "template = template[template[\"Coin\"].notnull()]\n",
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55c30ac8-fbe3-4334-b275-8e967daf0e46",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Vault Name'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m~/.conda/envs/waterfall_python/lib/python3.10/site-packages/pandas/core/indexes/base.py\u001B[0m in \u001B[0;36mget_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3360\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3361\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3362\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/waterfall_python/lib/python3.10/site-packages/pandas/_libs/index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/waterfall_python/lib/python3.10/site-packages/pandas/_libs/index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'Vault Name'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/q7/qhj4q23x49vb9f__hlp8t3280000gn/T/ipykernel_97935/3014421525.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;34m'''This is computing the ETHER collateral ratio for Aave and Compounds Celsius Borrows Account'''\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mborrow_account\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdefi_main\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mdefi_main\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'Vault Name'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m'Celsius Borrows Account'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0mcol_ratio\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mcol_threshold\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m2.0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mprotocols\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m'Compound'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'Aave V2'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/waterfall_python/lib/python3.10/site-packages/pandas/core/frame.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3456\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnlevels\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3457\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_getitem_multilevel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3458\u001B[0;31m             \u001B[0mindexer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3459\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mis_integer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindexer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3460\u001B[0m                 \u001B[0mindexer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mindexer\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/waterfall_python/lib/python3.10/site-packages/pandas/core/indexes/base.py\u001B[0m in \u001B[0;36mget_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3361\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3362\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3363\u001B[0;31m                 \u001B[0;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0merr\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3364\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3365\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mis_scalar\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0misna\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhasnans\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'Vault Name'"
     ]
    }
   ],
   "source": [
    "'''This is computing the ETHER collateral ratio for Aave and Compounds Celsius Borrows Account'''\n",
    "borrow_account = defi_main[defi_main['Vault Name'] == 'Celsius Borrows Account']\n",
    "col_ratio = {}\n",
    "col_threshold = 2.0\n",
    "protocols = ['Compound', 'Aave V2']\n",
    "\n",
    "grouped = borrow_account[borrow_account['Coin']=='ETH'].groupby('Protocol')['sum Original Balance'].sum()\n",
    "grouped = grouped/grouped.sum()\n",
    "\n",
    "for protocol in protocols:\n",
    "    temp = borrow_account[borrow_account['Protocol'] == protocol]\n",
    "    borrow = sum([bal for bal in temp['sum Balance $USD'] if bal<0])\n",
    "    ether = temp[temp['Coin']=='ETH']['sum Balance $USD'].values[0]\n",
    "    col_ratio[protocol] = max(abs(ether/borrow) - col_threshold,0) \n",
    "    col_ratio[protocol] /= abs(ether/borrow)\n",
    "    col_ratio[protocol + '_part'] = grouped[protocol]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "deployable.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# We format the deployable tab\n",
    "deployable_0 = deployable.copy()\n",
    "deployable_0 = deployable.iloc[1:,[1,8]]\n",
    "deployable_0.columns = deployable_0.iloc[0]\n",
    "deployable_0 = deployable_0.iloc[1:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294a88c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is generating a assets/liabilities dataframe for waterfall sheet\n",
    "coin_asset_liability = stats[[0,2,3]].copy()\n",
    "coin_asset_liability.columns = coin_asset_liability.iloc[0]\n",
    "coin_asset_liability.drop([0], inplace = True)\n",
    "coin_asset_liability.dropna(axis = 0 , how = \"all\", inplace = True)\n",
    "coin_asset_liability.reset_index(drop = True, inplace = True)\n",
    "coin_asset_liability.at[0, \"Coin/Asset\"] = \"Total\"\n",
    "coin_asset_liability = coin_asset_liability[coin_asset_liability[\"Coin/Asset\"].notnull()]\n",
    "coin_asset_liability.columns = ['Coin', 'Net Assets Total', 'Net Liabilities Total']\n",
    "coin_asset_liability[\"Net Assets Total\"] = coin_asset_liability[\"Net Assets Total\"].astype(\"float\")\n",
    "coin_asset_liability[\"Net Liabilities Total\"] = coin_asset_liability[\"Net Liabilities Total\"].astype(\"float\")\n",
    "#coin_asset_liability.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27226995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the coin price from coin recon sheet, there are some coins in FTX which are not listed in the \"coin stats\" tab\n",
    "# and have no price. I use FTX api to get their most recent price.\n",
    "coin_price = stats[[0,1]]\n",
    "coin_price.columns = [\"Coin\", \"Price\"]\n",
    "coin_price.drop([0], inplace = True)\n",
    "coin_price.dropna(axis = 0 , how = \"all\", inplace = True)\n",
    "coin_price = coin_price[coin_price[\"Coin\"].notnull()]\n",
    "coin_price.reset_index(drop = True, inplace = True)\n",
    "coin_price.loc[len(coin_price.index)] = ['Stable Coins', 1] \n",
    "srm_price = float(coin_price.loc[coin_price[\"Coin\"] == \"SRM\", \"Price\"])\n",
    "coin_price.loc[len(coin_price.index)] = ['SRM_LOCKED', srm_price] \n",
    "#coin_price\n",
    "\n",
    "\n",
    "existing_coins = coin_price[\"Coin\"].unique()\n",
    "coins_need_price = [\"ATLAS\", \"SOL\",\"POLIS\", \"RAY\", \"SLRS\", \"BVOL\", \"YFL\", \"QI\", \"CREAM\",\n",
    "                   \"FTT\", \"DASH\", \"THKD\", \"ALPHA\", \"WDGLD\", \"VSP\", \"ORBS\", \"WBTC\", \n",
    "                   \"3CRV\", \"KIN\", \"LRC\"]\n",
    "needed = []\n",
    "for coin in coins_need_price:\n",
    "    if coin not in existing_coins:\n",
    "        needed.append(coin)\n",
    "print(needed)\n",
    "price_dict ={\"Coin\": [], \"Price\": []}\n",
    "for coin in needed:\n",
    "    url1 = (f\"https://ftx.com/api/markets/{coin}/USD\")\n",
    "    data = requests.get(url1).json()\n",
    "    price_dict[\"Coin\"].append(coin)\n",
    "    price_dict[\"Price\"].append(data['result'][\"price\"])\n",
    "needed_price = pd.DataFrame.from_dict(price_dict)\n",
    "coin_price = pd.concat([coin_price, needed_price])\n",
    "needed_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5d88ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get coin tier info \n",
    "tiers = template[template[\"Coin\"]==\"Tier\"].T\n",
    "tiers.reset_index(inplace = True)\n",
    "tiers.columns = [\"Account\", \"Tier\"]\n",
    "tiers.drop([0], inplace = True)\n",
    "# there may be duplicate records in tier info\n",
    "tiers.drop_duplicates(inplace = True)\n",
    "# there are some rare occasions that the same account is assinged to two or more different tiers, use the first encountered\n",
    "# the others are likely for some testing purposes, which are usually added to the end \n",
    "tiers = tiers[~tiers.Account.duplicated()]\n",
    "filter4 = tiers['Tier'].isnull()\n",
    "tiers.at[filter4, \"Tier\"] = \"unassigned\"\n",
    "tiers[\"Tier\"] = tiers[\"Tier\"].astype(\"string\")\n",
    "#print(len(tiers))\n",
    "#print(len(tiers[tiers[\"Tier\"] == \"unassigned\"]))\n",
    "#print(tiers.Account.nunique())\n",
    "tiers[\"Tier\"] = tiers[\"Tier\"].apply(lambda x:x.split(\".\")[0])\n",
    "#tiers[\"Tier\"].unique()\n",
    "#tiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7d83e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# mapping each accout to a category\n",
    "categories = template[template[\"Coin\"].isin([\"Coin\", \"Category\"])].T\n",
    "categories.reset_index(drop = True, inplace = True)\n",
    "categories.columns = [\"Account\", \"Category\"]\n",
    "categories.drop([0], inplace = True)\n",
    "categories.Category.fillna(value = \"unassigned\", inplace = True)\n",
    "#print(len(categories))\n",
    "#print(len(categories[categories[\"Category\"] == \"unassigned\"]))\n",
    "#print(categories.Account.nunique())\n",
    "#categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8245bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the cofa data\n",
    "cofa_original = pd.read_excel(\"excel_input/coin_apy_template.xlsx\", sheet_name = \"COFA\")\n",
    "cofa_original.dropna(axis=0, how='all', inplace=True)\n",
    "cofa_original.reset_index(drop = True, inplace = True)\n",
    "#display(cofa_original)\n",
    "cofa_original.at[cofa_original[\"Coin\"] == \"stable (USD)\", \"Coin\"] = \"Stable Coins\"\n",
    "cofa_melt_cols = list(cofa_original.columns)\n",
    "cofa_melt_cols.remove(\"Coin\")\n",
    "#print(cofa_melt_cols)\n",
    "cofa = melt(cofa_original, cofa_melt_cols, \"Account\", \"COFA\")\n",
    "cofa = cofa[cofa[\"COFA\"].notnull()]\n",
    "cofa.reset_index(drop = True, inplace = True)\n",
    "#cofa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# process the carry tab (like the cofa)\n",
    "carry.dropna(axis=0, how='all', inplace=True)\n",
    "carry.reset_index(drop = True, inplace = True)\n",
    "#display(cofa_original)\n",
    "carry.at[carry[\"Coin\"] == \"stable (USD)\", \"Coin\"] = \"Stable Coins\"\n",
    "carry_melt_cols = list(carry.columns)\n",
    "carry_melt_cols.remove(\"Coin\")\n",
    "#print(cofa_melt_cols)\n",
    "carry2 = melt(carry, carry_melt_cols, \"Account\", \"CARRY\")\n",
    "carry2 = carry2[carry2[\"CARRY\"].notnull()]\n",
    "carry2.reset_index(drop = True, inplace = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c58826e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# process apy data\n",
    "apy = template[~template[\"Coin\"].isin([\"Coin\", \"Category\", \"Tier\"])]\n",
    "#apy.fillna(value = 0, inplace = True)\n",
    "\n",
    "# people leave spaces in the excel file sometimes, need to get rid of them\n",
    "apy.replace([\" \", \"\", \"  \"], np.nan, inplace = True)\n",
    "apy =apy[apy[\"Coin\"] != \"wBTC (Y/N)\"]\n",
    "#apy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb13048",
   "metadata": {},
   "outputs": [],
   "source": [
    "apy2 = apy.copy()\n",
    "apy2[\"Coin\"] = apy2[\"Coin\"] + \"_APY\"\n",
    "apy5 = apy2.T\n",
    "apy5.reset_index(inplace = True)\n",
    "apy5.columns = apy5.iloc[0]\n",
    "apy5.rename(columns = {\"Coin\": \"Account\"}, inplace = True)\n",
    "apy5.drop([0], inplace = True)\n",
    "#apy5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae71c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dyptes to float\n",
    "for col in apy5.columns:\n",
    "    if col != \"Account\":\n",
    "        apy5.loc[apy5[col].isin(template[\"Coin\"].unique()), col] = np.nan\n",
    "        apy5[col] = apy5[col].map(lambda x:np.nan if type(x)==str else x)\\\n",
    "            .astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65a35a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the user collateral and institutional collateral data in a dataframe\n",
    "# to be uploaded to waterfall sheet \n",
    "collateral = stats.copy()\n",
    "collateral_p1 = collateral.iloc[:, 0].to_frame()\n",
    "collateral_p1.columns = [\"Coin\"]\n",
    "collateral_p2 = collateral.iloc[:, 4:]\n",
    "collateral_p2.columns = collateral_p2.iloc[2]\n",
    "collateral = pd.concat([collateral_p1, collateral_p2[[\"User Collateral\", \"Inst Collateral\"]]], axis = 1)\n",
    "collateral.drop([0,1,2,3], inplace = True)\n",
    "collateral = collateral[collateral[\"Coin\"].notnull()]\n",
    "collateral[\"User Collateral\"] = -1 * collateral[\"User Collateral\"]\n",
    "collateral[\"Inst Collateral\"] = -1 * collateral[\"Inst Collateral\"]\n",
    "collateral.fillna(value = 0, inplace = True)\n",
    "collateral.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59083e70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# process stats table\n",
    "\n",
    "# first fill the \"asset\" or \"liability\" into row 0\n",
    "stats.iloc[0] = stats.iloc[0].ffill()\n",
    "# drop the secondary description of asset or liability (no use)\n",
    "stats.drop([1], inplace = True)\n",
    "\n",
    "#split stats into two parts, p1 is coin name and summary, p2 is assets/liabilities\n",
    "stats_p1 = stats.iloc[:, 0:3]\n",
    "stats_p1.columns = stats_p1.iloc[0]\n",
    "stats_p1.reset_index(drop = True, inplace = True)\n",
    "stats_p1.drop([0, 1, 2], inplace = True)\n",
    "stats_p1.rename(columns = {\"Coin/Asset\": \"Coin\"}, inplace = True)\n",
    "\n",
    "\n",
    "stats_p2 = stats.iloc[:, 4:]\n",
    "\n",
    "# filter according to \"assets\" and the detailed account name cannot be null\n",
    "stats_p3 = stats_p2.loc[:, stats_p2.loc[2].notnull()]\n",
    "stats_p4 = stats_p3.loc[:, stats_p3.loc[0] == \"Assets\"]\n",
    "stats_p4.reset_index(drop = True, inplace = True)\n",
    "stats_p4.columns = stats_p4.iloc[1]\n",
    "stats_p4.reset_index(drop = True, inplace = True)\n",
    "stats_p4.drop([0, 1, 2], inplace = True)\n",
    "stats = pd.concat([stats_p1[\"Coin\"], stats_p4], axis = 1)\n",
    "stats = stats[stats[\"Coin\"].notnull()]\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a056e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c73a994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process DeFi assets data\n",
    "defi_p1 = defi.iloc[:, 0:3]\n",
    "defi_p1.drop([0, 1, 2], inplace = True)\n",
    "defi_p1.rename(columns = {\"Coin/Asset\": \"Coin\"}, inplace = True)\n",
    "defi_p1\n",
    "defi_p2 = defi.iloc[:, 3:]\n",
    "\n",
    "# filter according the detailed account name cannot be null\n",
    "defi_p3 = defi_p2.loc[:, defi_p2.iloc[1].notnull()]\n",
    "defi_p3.reset_index(drop = True, inplace = True)\n",
    "defi_p3.columns = defi_p3.iloc[1]\n",
    "defi_p3.reset_index(drop = True, inplace = True)\n",
    "defi_p3.drop([0, 1, 2], inplace = True)\n",
    "defi_p3\n",
    "defi = pd.concat([defi_p1[\"Coin\"], defi_p3], axis = 1)\n",
    "defi = defi[defi[\"Coin\"].notnull()]\n",
    "#defi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb484dc-4965-4de4-af82-d372866f5d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e49690-34a5-4042-93fc-cee98f041af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "defi[defi['Coin']=='ETH']['Celsius Borrows Account']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "col_ratio"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b364cf-2883-4c86-9518-92c7063de1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD GAB - SPLIT ON OVERCOLLATERIZED ETH IN CELSIUS BORROWS ACCOUNT\n",
    "borrow_eth = defi[defi['Coin']=='ETH']['Celsius Borrows Account'].iloc[0]\n",
    "idx_eth = defi[defi['Coin']=='ETH'].index[0]\n",
    "for col in ['Aave V2', 'Compound']:\n",
    "    new_col = f'Overcollaterized - {col}'\n",
    "    defi[new_col] = 0\n",
    "    defi.at[idx_eth,new_col] = borrow_eth * col_ratio[col+'_part']* col_ratio[col]\n",
    "    defi.at[idx_eth,'Celsius Borrows Account'] -= defi.at[idx_eth,new_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b85b58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process ftx summary data\n",
    "ftx.dropna(axis = 0 , how = \"all\", inplace = True)\n",
    "ftx.dropna(axis = 1 , how = \"all\", inplace = True)\n",
    "filter_ftx = ((ftx[\"Total Asset\"] == 0) & (ftx[\"Total Borrow\"] == 0))\n",
    "ftx = ftx[(ftx[ftx.columns[0]].notnull()) & ~filter_ftx]\n",
    "ftx.drop(columns = [\"Total Asset\", \"Total Borrow\"], inplace = True)\n",
    "ftx_cols = []\n",
    "for col in ftx.columns:\n",
    "    ftx_cols.append(\"FTX - \" + col)\n",
    "ftx.columns = ftx_cols\n",
    "ftx.rename(columns = {ftx.columns[0]: \"Coin\"}, inplace = True)\n",
    "\n",
    "# below lines of code will merge BTC and WBTC together\n",
    "ftx_btc = ftx[ftx[\"Coin\"].isin([\"BTC\", \"WBTC\"])]\n",
    "ftx_btc = ftx_btc.append(ftx_btc.sum(numeric_only=True), ignore_index=True)\n",
    "ftx_btc = ftx_btc[~ftx_btc[\"Coin\"].isin([\"BTC\", \"WBTC\"])]\n",
    "ftx_btc.reset_index(drop = True, inplace = True)\n",
    "ftx_btc.loc[0, \"Coin\"] = \"BTC\"\n",
    "ftx = pd.concat([ftx_btc, ftx[~ftx[\"Coin\"].isin([\"BTC\", \"WBTC\"])]])\n",
    "#ftx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35174754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get update date and time\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "#print(\"Updated at:\", dt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73eb1dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the stable coins, these coins are listed together under \"stable coins\" in waterfall sheet\n",
    "stables = ['alUSD','BUSD', 'GUSD', 'LUSD', 'LUSD Curve','MCDAI', 'PAX', 'SUSD', 'TUSD', \n",
    "           'USDC', 'USDT ERC20', 'ZUSD', \"USD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e05b438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Tier dataframe for merging purpose\n",
    "tier_dict = {\"Tier\":[\"1\", \"2\", \"3\", \"4\", \"5\", \"unassigned\"]}\n",
    "coin_tiers = pd.DataFrame.from_dict(tier_dict)\n",
    "coin_tiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "apy['DD - BANCOR - WBTC']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "apy5[apy5['Account'] =='DD - BANCOR - WBTC']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2f6799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge 3 dataframes together, coin stats/Defi assets/FTX summary\n",
    "coin_stats = stats.merge(defi, on = \"Coin\", how = \"outer\")\n",
    "coin_stats = coin_stats.merge(ftx, on = \"Coin\", how = \"outer\")\n",
    "coin_stats.fillna(value = 0, inplace = True)\n",
    "coin_stats_col = []\n",
    "for col in coin_stats.columns:\n",
    "    coin_stats_col.append(col.strip())\n",
    "coin_stats.columns = coin_stats_col\n",
    "len(coin_stats.columns)\n",
    "coin_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d83792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of coins in the above dataframe and add \"Stable Coins\" into that list\n",
    "coin_list = list(coin_stats[\"Coin\"].unique())\n",
    "coin_list.append(\"Stable Coins\")\n",
    "#coin_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8871cf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list = np.asarray(tiers[\"Account\"])\n",
    "len(acc_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154331b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this block and the following block are meant to show which accounts from coin recon sheet are not listed \n",
    "# in tier/apy sheet, or which accounts listed in the tier/apy data no longer exists in coin recon sheet\n",
    "not_covered = []\n",
    "for col in coin_stats.columns:\n",
    "    if col not in acc_list:\n",
    "        not_covered.append(col)\n",
    "not_covered    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399afa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_covered = []\n",
    "for col in acc_list:\n",
    "    if col not in coin_stats.columns:\n",
    "        not_covered.append(col)\n",
    "not_covered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41af1d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose coin_stats to get it in right shape\n",
    "account_toremove = ['DeFi Borrows - Assets', 'DeFi Assets - Assets', \"FTX\",\n",
    "                   \"DeFi Borrows - Collateral\", \"DeFi Borrows - Tokens\"]\n",
    "coin_stats_t = coin_stats.T\n",
    "new_header = coin_stats_t.iloc[0] #grab the first row for the header\n",
    "coin_stats_t = coin_stats_t[1:] #take the data less the header row\n",
    "coin_stats_t.columns = new_header #set the header row as the df header\n",
    "coin_stats_t.reset_index(inplace = True)\n",
    "coin_stats_t.rename(columns={coin_stats_t.columns[0]: \"Account\" }, inplace = True)\n",
    "coin_stats_t.reset_index(drop=True, inplace = True)\n",
    "#coin_stats_t = coin_stats_t[coin_stats_t[\"Account\"] != \"Defi Assets\"]\n",
    "coin_stats_t = coin_stats_t[~coin_stats_t[\"Account\"].isin(account_toremove)]\n",
    "\n",
    "#coin_stats_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "coin_stats_t.loc[coin_stats_t['Account'] == 'DD - CONVEX - XUAT', stables]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f2673f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding Tier info \n",
    "coin_stat_tier = tiers.merge(coin_stats_t, on = \"Account\", how = \"right\")\n",
    "#coin_stat_tier[\"Tier\"].fillna(value = \"unknown\", inplace = True)\n",
    "\n",
    "coin_stat_tier['Stable Coins']= coin_stat_tier[stables].sum(axis=1)\n",
    "coin_stat_tier.to_excel(\"excel_outputs/coin_stats_tier_live.xlsx\", index = False)\n",
    "\n",
    "#print(len(coin_stat_tier[coin_stat_tier[\"Tier\"] == \"unknown\"]))\n",
    "coin_stat_tier[\"Tier\"] = coin_stat_tier[\"Tier\"].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbdf14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to calculate stable coin apy, we need to calculate for each stable coin yield = # of each stable coin * apy of each stable\n",
    "# and stable coin apy = sum of all stable coin yiled / total # of stable coins\n",
    "# this prepares a list of columns needed to be summed.\n",
    "stable_yield = []\n",
    "for coin in stables:\n",
    "    stable_yield.append(coin+\"_yield\")\n",
    "stable_yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515da3a8-46d7-4ae0-bfb7-a5cb97aad39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD --------------------------\n",
    "# ------------------------------\n",
    "# I need to add a function that will fill _APY columns with the default values\n",
    "def default_fill(row):\n",
    "    if ~ np.isnan(row['Default_APY']): \n",
    "        row.loc[apy_cols] = row[apy_cols].fillna(row['Default_APY'])\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "coin_stat_tier.loc[coin_stat_tier['Account']=='DD - SNX', stables]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5eda05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the yield = # of coins * apy for each coin\n",
    "coin_stat_tier_apy = coin_stat_tier.merge(apy5, on = \"Account\", how = \"left\")\n",
    "#coin_stat_tier_apy.fillna(value = 0, inplace = True)\n",
    "\n",
    "# --------- ADD GAB - Replace NA APY by the corresponding Default APY values if it exists -------------------\n",
    "apy_cols = ['_APY' in col for col in coin_stat_tier_apy.columns]\n",
    "coin_stat_tier_apy = coin_stat_tier_apy.apply(default_fill, axis=1, result_type='broadcast')\n",
    "coin_stat_tier_apy['Stable Coins'] = coin_stat_tier_apy['Stable Coins'].astype(np.float64)\n",
    "coin_stat_tier_apy = coin_stat_tier_apy.loc[:,~coin_stat_tier_apy.columns.duplicated()]\n",
    "#coin_stat_tier_apy.to_excel(\"C:/celsius/Liquidity/coin_stat_tier_apy.xlsx\", index = False)\n",
    "for coin in coin_list:\n",
    "    #print(coin)\n",
    "    yield_name = coin + \"_yield\"\n",
    "    coin_apy = coin + \"_APY\"\n",
    "    if coin_apy in coin_stat_tier_apy.columns:\n",
    "        coin_stat_tier_apy[yield_name] = coin_stat_tier_apy[coin] * coin_stat_tier_apy[coin_apy]\n",
    "    else:\n",
    "        coin_stat_tier_apy[yield_name] = 0\n",
    "        coin_stat_tier_apy[coin_apy] = np.nan\n",
    "coin_stat_tier_apy['Stable Coins_yield']= coin_stat_tier_apy[stable_yield].sum(axis=1)\n",
    "coin_stat_tier_apy['Stable Coins_APY']= coin_stat_tier_apy['Stable Coins_yield']/ coin_stat_tier_apy['Stable Coins']\n",
    "#coin_stat_tier_apy.to_excel(\"coin_stat_tier_apy.xlsx\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6736761e-1a44-47a0-ba9a-8fbf51c0e8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "apy_cols = ['_APY' in col for col in coin_stat_tier_apy.columns]\n",
    "coin_stat_tier_apy.loc[:,apy_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cd242e-2759-4a3a-95dd-58eaaa9ee937",
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_stat_tier_apy[coin_stat_tier_apy['Account'] == 'Maker Borrows Vault']['WBTC_APY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf1d259-7e77-4686-b356-d5d202f966d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_tiers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610992f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each coin, groupy by tier so we have a dataframe containing coin level tier data\n",
    "# also calculating the apy for each coin on tier level\n",
    "for coin in coin_list:\n",
    "    #print(coin)\n",
    "    coin_yield = coin+\"_yield\"\n",
    "    coin_apy = coin+\"_APY\"\n",
    "    df1 = coin_stat_tier_apy[[coin, coin_yield, \"Tier\"]]\n",
    "    df2 = df1.groupby('Tier', as_index = False).agg({coin: \"sum\",\n",
    "                                                    coin_yield: \"sum\"})\n",
    "    df2[coin_apy] = df2[coin_yield]/ df2[coin]\n",
    "    df2.drop(columns = [coin_yield], inplace = True)\n",
    "    #display(df2)\n",
    "    coin_tiers = coin_tiers.merge(df2, on = \"Tier\", how = \"left\")\n",
    "coin_tiers.fillna(value = 0, inplace = True)\n",
    "#coin_tiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f26e67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coin_tier_p1_cols = [\"Tier\"]\n",
    "coin_tier_p2_cols = [\"Tier\"]\n",
    "filter2 = coin_tiers[\"Tier\"] != \"unassigned\"\n",
    "for col in coin_tiers.columns:\n",
    "    if col != \"Tier\" and \"_APY\" in col:\n",
    "        coin_tier_p2_cols.append(col)\n",
    "    elif col != \"Tier\":\n",
    "        coin_tier_p1_cols.append(col)\n",
    "    else:\n",
    "        pass\n",
    "#print(len(coin_tier_p1_cols))\n",
    "#len(coin_tier_p2_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4d3791",
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_tier_p1 = coin_tiers[filter2][coin_tier_p1_cols].T\n",
    "coin_tier_p1.reset_index(inplace = True)\n",
    "coin_tier_p1.columns = coin_tier_p1.iloc[0]\n",
    "coin_tier_p1.drop([0], inplace = True)\n",
    "new_name = [\"Coin\"]\n",
    "for col in coin_tier_p1.columns:\n",
    "    if col != \"Tier\":\n",
    "        new_name.append(\"Coin_Tier_\"+str(col)[0])\n",
    "coin_tier_p1.columns = new_name\n",
    "#coin_tier_p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c2d1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_tier_p2 = coin_tiers[filter2][coin_tier_p2_cols]\n",
    "coin_tier_p2.columns = coin_tier_p1_cols\n",
    "coin_tier_p2 = coin_tier_p2.T\n",
    "coin_tier_p2.reset_index(inplace = True)\n",
    "coin_tier_p2.columns = coin_tier_p2.iloc[0]\n",
    "coin_tier_p2.drop([0], inplace = True)\n",
    "new_name = [\"Coin\"]\n",
    "for col in coin_tier_p2.columns:\n",
    "    if col != \"Tier\":\n",
    "        new_name.append(\"APY_Tier_\"+str(col)[0])\n",
    "coin_tier_p2.columns = new_name\n",
    "#coin_tier_p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a542fcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_tiers = coin_tier_p1.merge(coin_tier_p2, on = \"Coin\", how = \"inner\")\n",
    "filter3 = ~coin_tiers[\"Coin\"].isin(stables)\n",
    "#coin_tiers.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6776763b",
   "metadata": {},
   "source": [
    "## the below code is to generat the pivot_data tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2249d1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df1 dataframe\n",
    "some_dict = {\"Coin\":[], \"Category\":[], \"Account\": [], \"Tier\": [], \"# of Coins\": [], \"APY\": []}\n",
    "df1 = pd.DataFrame.from_dict(some_dict)\n",
    "col_names = [\"Coin\", \"Category\", \"Account\", \"Tier\", \"# of Coins\",\n",
    "             \"APY\", \"COFA\", \"USD Value\", \"USD Value * COFA\",\n",
    "             \"USD Value * APY\", \"Deployment Status\", \"Manual\", \"CARRY\",\n",
    "             \"USD Value * CARRY\", \"WBTC\"]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "coin_stat_tier_apy[coin_stat_tier_apy['Account'] == 'DD - CONVEX - XUAT']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9ba65a-50e0-41ba-9330-2dc620962765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill df1 Dataframe coin by coin\n",
    "for coin in coin_list:\n",
    "    if coin not in stables:\n",
    "        used_cols = [\"Account\", \"Tier\", coin, coin+\"_APY\"]\n",
    "        df2 = categories.merge(coin_stat_tier_apy[used_cols], on = \"Account\", how = \"right\")\n",
    "        df2[\"Coin\"] = coin\n",
    "        df2.rename(columns = {coin: \"# of Coins\", coin+\"_APY\": \"APY\"}, inplace = True)\n",
    "        df1 = pd.concat([df1, df2])\n",
    "\n",
    "filter1 = df1[\"# of Coins\"] > 10e-6\n",
    "df1 = df1[filter1]\n",
    "cats = list(df1[\"Category\"].unique())\n",
    "accs = list(df1[\"Account\"].unique())\n",
    "cofa_accts = list(cofa[\"Account\"].unique())\n",
    "cofa_accts.remove(\"Default\")\n",
    "carry_accts = list(carry2[\"Account\"].unique())\n",
    "carry_accts.remove(\"Default\")\n",
    "#cofa_accts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "carry2.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863d16f7-f4f5-4fe9-a4cd-7d6be885920a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cofa\n",
    "def add_cofa_carry(df1, cofa, cofa_accts, tab=\"COFA\"):\n",
    "    default_cofa = cofa[cofa[\"Account\"] == \"Default\"][[\"Coin\", tab]]\n",
    "    df2 = df1.merge(default_cofa, on = \"Coin\", how = \"left\")\n",
    "    for col in cofa_accts:\n",
    "        #print(col)\n",
    "        cofa_2 = cofa[cofa[\"Account\"] == col]\n",
    "        if col in cats:\n",
    "            cofa_2.columns = [\"Coin\", \"Category\", f\"{tab}-2\"]\n",
    "            df2 = df2.merge(cofa_2, on=[\"Coin\", \"Category\"], how='left')\n",
    "        elif col in accs:\n",
    "            cofa_2.columns = [\"Coin\", \"Account\", f\"{tab}-2\"]\n",
    "            df2 = df2.merge(cofa_2, on=[\"Coin\", \"Account\"], how='left')\n",
    "        else:\n",
    "            continue\n",
    "        df2_p1 = df2[df2[f\"{tab}-2\"].isnull()].drop(columns = [f\"{tab}-2\"])\n",
    "        df2_p2 = df2[df2[f\"{tab}-2\"].notnull()]\n",
    "        df2_p2[tab] = df2_p2[f\"{tab}-2\"]\n",
    "        df2_p2.drop(columns = [f\"{tab}-2\"], inplace = True)\n",
    "        df2 = pd.concat([df2_p1, df2_p2])\n",
    "        df2.sort_values(by = [\"Coin\"], inplace = True)\n",
    "    return df2\n",
    "df2 = add_cofa_carry(df1, cofa, cofa_accts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d104ecb3-5110-4037-9798-38d7a52ecce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Manual Adjustements\n",
    "manual_adjustements['Manual'] = True\n",
    "df2['Manual'] = False\n",
    "df2 = pd.concat([df2,manual_adjustements]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Add Deployement Status\n",
    "total_stable = deployable_0[deployable_0['Coin'].isin(stables)]['Total Undeployed (Coins)'].sum()\n",
    "deployable_0 = deployable_0.append({'Coin':'Stable Coins',\n",
    "                     'Total Undeployed':total_stable}, ignore_index=True)\n",
    "df2['Deployment Status'] = 'Deployed'\n",
    "undeployed_accounts = df2[df2['Category'].isin(['undeployed','Undeployed'])]['Account'].unique().tolist()\n",
    "# UK First than US\n",
    "first_accounts = ['Celsius Network Limited (UK)', 'Celsius Network LLC (US)' ]\n",
    "undeployed_accounts = [x for x in undeployed_accounts if x not in (first_accounts)]\n",
    "undeployed_accounts = first_accounts + undeployed_accounts\n",
    "\n",
    "#undeployed_accounts = np.unique(first_accounts + undeployed_accounts)\n",
    "cond = df2['Account'] == 'Celsius Network LLC (US)'\n",
    "df2['# of Coins'].fillna(0, inplace=True)\n",
    "for account in undeployed_accounts:\n",
    "    for coin in deployable_0['Coin']:\n",
    "        cond1 = (df2['Account'] == account) & (df2['Coin'] == coin)\n",
    "        cond2 = deployable_0['Coin'] == coin\n",
    "        if sum(cond1)+sum(cond2)<2: continue\n",
    "\n",
    "        if df2[cond1]['# of Coins'].values < deployable_0[cond2]['Total Undeployed'].values:\n",
    "            deployable_0.loc[cond2, 'Total Undeployed'] -= df2.loc[cond1, '# of Coins'].values\n",
    "            df2.loc[cond1, 'Deployment Status'] = 'Deployable'\n",
    "        else:\n",
    "            df2.loc[cond1, '# of Coins'] -= deployable_0.loc[cond2, 'Total Undeployed'].values\n",
    "            df2.loc[cond1, 'Deployment Status'] = 'Liquidity Reserve'\n",
    "            new_row = df2.loc[cond1]\n",
    "            if  deployable_0.loc[cond2, 'Total Undeployed'].values>0:\n",
    "                new_row['# of Coins'] = deployable_0.loc[cond2, 'Total Undeployed'].values\n",
    "                new_row['Deployment Status'] = 'Deployable'\n",
    "                df2 = df2.append(new_row, ignore_index=True)\n",
    "                deployable_0.loc[cond2, 'Total Undeployed'] = 0\n",
    "\n",
    "df2.loc[df2['Category'] == 'Underdeployed', 'Deployment Status'] = 'Deployable'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b60a61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df2.to_excel(\"excel_outputs/cofa_2.xlsx\", index = False)\n",
    "# Add Price\n",
    "df2 = df2.merge(coin_price, on = \"Coin\", how = \"left\")\n",
    "df2[\"USD Value\"] = df2[\"# of Coins\"] * df2[\"Price\"]\n",
    "df2[\"USD Value * APY\"] = df2[\"USD Value\"] * df2[\"APY\"]\n",
    "df2[\"Tier\"] = df2[\"Tier\"].astype(str).apply(lambda x:x.split(\".\")[0])\n",
    "\n",
    "df2[\"USD Value * COFA\"] = df2[\"USD Value\"] * df2[\"COFA\"]\n",
    "df2.sort_values(by = \"USD Value\", ascending = False, inplace = True)\n",
    "df2['Category'] = df2['Category'].str.strip()\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa64526e-6416-472c-9669-94ade4cfa636",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADD CARRY\n",
    "df2 = add_cofa_carry(df2, carry2, carry_accts, tab='CARRY')\n",
    "df2[\"USD Value * CARRY\"] = df2[\"USD Value\"] * df2[\"CARRY\"]\n",
    "df2.sort_values(by = \"USD Value\", ascending = False, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Merge WBTC and BTC\n",
    "df2['WBTC'] = 'N'\n",
    "df2.loc[df2['Coin'] == 'WBTC', 'WBTC'] = 'Y'\n",
    "df2['Coin'] = df2['Coin'].replace('WBTC', 'BTC')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5b9bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the collateral table and insert it into the liquidity tier summary\n",
    "# for COFA value of collateral, use default first, there is a \"Collateral\" column in COFA which will override the default\n",
    "cofa_collateral_p1 = cofa_original[cofa_original[\"Collateral\"].notnull()]\n",
    "cofa_collateral_p2 = cofa_original[cofa_original[\"Collateral\"].isnull()]\n",
    "cofa_collateral_p1[\"Default\"] = cofa_collateral_p1[\"Collateral\"]\n",
    "cofa_collateral = pd.concat([cofa_collateral_p1, cofa_collateral_p2])[[\"Coin\", \"Default\"]]\n",
    "cofa_collateral.columns = [\"Coin\", \"COFA\"]\n",
    "# Carry process\n",
    "carry_collateral_p1 = carry[carry[\"Collateral\"].notnull()]\n",
    "carry_collateral_p2 = carry[carry[\"Collateral\"].isnull()]\n",
    "carry_collateral_p1[\"Default\"] = carry_collateral_p1[\"Collateral\"]\n",
    "carry_collateral = pd.concat([carry_collateral_p1, carry_collateral_p2])[[\"Coin\", \"Default\"]]\n",
    "carry_collateral.columns = [\"Coin\", \"CARRY\"]\n",
    "\n",
    "# collateral tab\n",
    "collateral = collateral.merge(cofa_collateral, on = \"Coin\", how = \"left\")\n",
    "collateral = collateral.merge(carry_collateral, on = \"Coin\", how = \"left\")\n",
    "collateral = collateral.merge(coin_price, on = \"Coin\", how = \"left\")\n",
    "collateral[\"User Collateral USD Value\"] = collateral[\"User Collateral\"] * collateral[\"Price\"]\n",
    "collateral[\"Inst Collateral USD Value\"] = collateral[\"Inst Collateral\"] * collateral[\"Price\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f958930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the whole apy-template table and insert it into the liquidity tier summary\n",
    "apy_template = template.drop([0])\n",
    "apy_template.fillna(value = \"N/A\", inplace = True)\n",
    "apy_template.replace([\" \", \"\", \"  \"], \"N/A\", inplace = True)\n",
    "apy_template.columns = apy_template.columns.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e2b994-80db-42cf-b5c5-f6aecd57e445",
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_tiers[filter3].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac0b7b0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "path = \"excel_outputs/Liquidity_Tier_Summary Live.xlsx\"\n",
    "lp = openpyxl.load_workbook(path)\n",
    "lp.remove(lp['Data'])\n",
    "lp.remove(lp['Price'])\n",
    "lp.remove(lp['Pivot_Data'])\n",
    "lp.remove(lp['APY'])\n",
    "lp.remove(lp['COFA'])\n",
    "lp.remove(lp['Collateral'])\n",
    "writer = pd.ExcelWriter(path, engine = 'openpyxl')\n",
    "writer.book = lp\n",
    "coin_tiers[filter3].to_excel(writer, sheet_name = 'Data', index = False)\n",
    "coin_price.to_excel(writer, sheet_name = 'Price', index = False)\n",
    "df2[col_names].to_excel(writer, sheet_name = 'Pivot_Data', index = False)\n",
    "apy_template.to_excel(writer, sheet_name = 'APY', index = False)\n",
    "cofa_original.to_excel(writer, sheet_name = 'COFA', index = False)\n",
    "collateral.to_excel(writer, sheet_name = 'Collateral', index = False)\n",
    "writer.close()\n",
    "lp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28e306e",
   "metadata": {},
   "source": [
    "## following code will push the data to the shared google sheet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9605267e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0024925a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scope = [\n",
    "'https://www.googleapis.com/auth/spreadsheets',\n",
    "'https://www.googleapis.com/auth/drive',\n",
    "]\n",
    "last_updated = \"Updated at - \" + dt.datetime.utcnow().strftime(\"%m/%d/%Y, %H:%M:%S\") +'UTC'\n",
    "# this is ID for testing\n",
    "#SPREADSHEET_ID = '1IptNC0hEhwvuyfI4m2kP9-rR-3jDAOhgQaPNkW2I_QQ'\n",
    "# this is ID for waterfall sheet\n",
    "SPREADSHEET_ID = \"1ZkSLZH2QwHnfdSpQUWAv2qum6xzhemngjWQBJBn_KeM\" #Real Last\n",
    "#SPREADSHEET_ID = \"1lw17fQ-oRTXPBVSDkiMGfWemtXGwzruCgsHjYBxlYoU\" # LAST Test\n",
    "# The file token.json stores the user's access and refresh tokens, and is\n",
    "# created automatically when the authorization flow completes for the first\n",
    "# time.\n",
    "if os.path.exists('write_token.json'):\n",
    "        creds = Credentials.from_authorized_user_file('write_token.json', scope)\n",
    "'''flow = InstalledAppFlow.from_client_secrets_file('client_secret_992941975507-pvjneopi7dhmj2mqq6arpghs6r7q31jj.json', scope)\n",
    "creds = flow.run_local_server(port=0)\n",
    "with open('write_token.json', 'w') as token:\n",
    "    token.write(creds.to_json())'''\n",
    "service = build('sheets', 'v4', credentials=creds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447954ca-2099-4bdf-a803-90d495b9ab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = service.spreadsheets().values().update(\n",
    "    spreadsheetId=SPREADSHEET_ID,\n",
    "    valueInputOption='RAW',\n",
    "    range=\"Categories!A1\",\n",
    "    body=dict(\n",
    "        majorDimension='ROWS',\n",
    "        values=[[last_updated]]\n",
    ")\n",
    ").execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "coin_tiers[filter3].head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4569bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = service.spreadsheets().values().clear(\n",
    "    spreadsheetId=SPREADSHEET_ID,\n",
    "    range=\"Data\",\n",
    "    ).execute()\n",
    "\n",
    "response = service.spreadsheets().values().update(\n",
    "    spreadsheetId=SPREADSHEET_ID,\n",
    "    valueInputOption='RAW',\n",
    "    range=\"Data!A1\",\n",
    "    body=dict(\n",
    "        majorDimension='ROWS',\n",
    "        values=coin_tiers[filter3].fillna(value = \"N/A\").T.reset_index().T.values.tolist())\n",
    ").execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b8488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = service.spreadsheets().values().clear(\n",
    "    spreadsheetId=SPREADSHEET_ID,\n",
    "    range=\"Price\",\n",
    "    ).execute()\n",
    "\n",
    "response = service.spreadsheets().values().update(\n",
    "    spreadsheetId=SPREADSHEET_ID,\n",
    "    valueInputOption='RAW',\n",
    "    range=\"Price!A1\",\n",
    "    body=dict(\n",
    "        majorDimension='ROWS',\n",
    "        values=coin_price.fillna(value = 0).T.reset_index().T.values.tolist())\n",
    ").execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5115989c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response = service.spreadsheets().values().clear(\n",
    "    spreadsheetId=SPREADSHEET_ID,\n",
    "    range=\"APY\",\n",
    "    ).execute()\n",
    "\n",
    "response = service.spreadsheets().values().update(\n",
    "    spreadsheetId=SPREADSHEET_ID,\n",
    "    valueInputOption='RAW',\n",
    "    range=\"APY!A1\",\n",
    "    body=dict(\n",
    "        majorDimension='ROWS',\n",
    "        values=apy_template.fillna(value = 0).T.reset_index().T.values.tolist())\n",
    ").execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d15a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = service.spreadsheets().values().clear(\n",
    "    spreadsheetId=SPREADSHEET_ID,\n",
    "    range=\"COFA\",\n",
    "    ).execute()\n",
    "\n",
    "response = service.spreadsheets().values().update(\n",
    "    spreadsheetId=SPREADSHEET_ID,\n",
    "    valueInputOption='RAW',\n",
    "    range=\"COFA!A1\",\n",
    "    body=dict(\n",
    "        majorDimension='ROWS',\n",
    "        values=cofa_original.fillna(value = \"N/A\").T.reset_index().T.values.tolist())\n",
    ").execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "response = service.spreadsheets().values().clear(\n",
    "    spreadsheetId=SPREADSHEET_ID,\n",
    "    range=\"CARRY\",\n",
    "    ).execute()\n",
    "\n",
    "response = service.spreadsheets().values().update(\n",
    "    spreadsheetId=SPREADSHEET_ID,\n",
    "    valueInputOption='RAW',\n",
    "    range=\"CARRY!A1\",\n",
    "    body=dict(\n",
    "        majorDimension='ROWS',\n",
    "        values=carry.fillna(value = \"N/A\").T.reset_index().T.values.tolist())\n",
    ").execute()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79887900",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = service.spreadsheets().values().clear(\n",
    "    spreadsheetId=SPREADSHEET_ID,\n",
    "    range=\"Collateral\",\n",
    "    ).execute()\n",
    "\n",
    "response = service.spreadsheets().values().update(\n",
    "    spreadsheetId=SPREADSHEET_ID,\n",
    "    valueInputOption='RAW',\n",
    "    range=\"Collateral!A1\",\n",
    "    body=dict(\n",
    "        majorDimension='ROWS',\n",
    "        values=collateral.fillna(value = \"N/A\").T.reset_index().T.values.tolist())\n",
    ").execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31088a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = service.spreadsheets().values().clear(\n",
    "    spreadsheetId=SPREADSHEET_ID,\n",
    "    range=\"Coin_Total_Asset_Liability\",\n",
    "    ).execute()\n",
    "\n",
    "response = service.spreadsheets().values().update(\n",
    "    spreadsheetId=SPREADSHEET_ID,\n",
    "    valueInputOption='RAW',\n",
    "    range=\"Coin_Total_Asset_Liability!A1\",\n",
    "    body=dict(\n",
    "        majorDimension='ROWS',\n",
    "        values=coin_asset_liability.fillna(value = 0).T.reset_index().T.values.tolist())\n",
    ").execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b66f7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = service.spreadsheets().values().clear(\n",
    "    spreadsheetId=SPREADSHEET_ID,\n",
    "    range=\"Pivot_Data\",\n",
    "    ).execute()\n",
    "\n",
    "response = service.spreadsheets().values().update(\n",
    "    spreadsheetId=SPREADSHEET_ID,\n",
    "    valueInputOption='RAW',\n",
    "    range=\"Pivot_Data!A1\",\n",
    "    body=dict(\n",
    "        majorDimension='ROWS',\n",
    "        values=df2[col_names].fillna(value = \"N/A\").T.reset_index().T.values.tolist())\n",
    ").execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135b1d61",
   "metadata": {},
   "source": [
    "## below code is for storing historical data with a date label "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106aa03f-49fd-4d1f-a9be-82eb9bd5cb08",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# get update date and time\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(\"Updated at:\", dt_string)\n",
    "date_string = dt_string[0:10]\n",
    "date_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f917d4-5b26-4b47-8828-4f7e7ec01b08",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "coin_tiers[\"Date\"] = date_string\n",
    "df2[\"Date\"] = date_string\n",
    "df2_col_names = [\"Date\", \"Coin\", \"Category\", \"Account\", \"Tier\", \"# of Coins\", \n",
    "             \"APY\", \"COFA\", \"Price\", \"USD Value\", \"USD Value * COFA\",\n",
    "             \"USD Value * APY\"]\n",
    "coin_tiers_col_names = ['Date', 'Coin', 'Coin_Tier_1', 'Coin_Tier_2', 'Coin_Tier_3', 'Coin_Tier_4',\n",
    "       'Coin_Tier_5', 'APY_Tier_1', 'APY_Tier_2', 'APY_Tier_3', 'APY_Tier_4',\n",
    "       'APY_Tier_5']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76335811-6f93-49d8-9868-1166e22f8800",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Read the liquidity data excel file and apppend new data to it\n",
    "#path = \"/home/fan7893/Documents/Celsius/Liquidity/Liquidity_Tier_Data.xlsx\"\n",
    "#path = \"excel_input/Liquidity_Tier_Summary Live.xlsx\"\n",
    "data = coin_tiers[filter3].fillna(value = \"N/A\")\n",
    "pivot_data = df2[col_names].fillna(value = \"N/A\")\n",
    "\n",
    "# there may be some null values due to excel operation, need to filter them out\n",
    "data = data[data[\"Date\"].notnull()]\n",
    "#pivot_data = pivot_data[pivot_data[\"Date\"].notnull()]\n",
    "\n",
    "# if running for multiple times for the same date, we need to replace the previous run data from same date\n",
    "data = data[data[\"Date\"] != date_string]\n",
    "#pivot_data = pivot_data[pivot_data[\"Date\"] != date_string]\n",
    "\n",
    "data = pd.concat([data, coin_tiers[filter3][coin_tiers_col_names]])\n",
    "pivot_data = pd.concat([pivot_data, df2[df2_col_names]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51d75cc-98fb-4f99-972f-deed1966fa31",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# reinsert the updated data into the template\n",
    "writer = pd.ExcelWriter(path)\n",
    "\n",
    "# add format info\n",
    "workbook = writer.book\n",
    "format1 = workbook.add_format({'num_format': '$#,##0', \"align\": \"left\"})\n",
    "format2 = workbook.add_format({'num_format': '#,##0.00%', \"align\": \"left\"})\n",
    "format3 = workbook.add_format({'num_format': '#,##0.00', \"align\": \"left\"})\n",
    "format4 = workbook.add_format({'num_format': '$#,##0.00', \"align\": \"left\"})\n",
    "data.to_excel(writer, sheet_name = 'Data', index = False)\n",
    "pivot_data.to_excel(writer, sheet_name = 'Pivot_Data', index = False)\n",
    "\n",
    "# set format\n",
    "worksheet = writer.sheets[\"Data\"]\n",
    "worksheet.set_column('A:B', 16)\n",
    "worksheet.set_column('C:G', 18, format3)\n",
    "worksheet.set_column('H:L', 18, format2)\n",
    "worksheet = writer.sheets[\"Pivot_Data\"]\n",
    "worksheet.set_column('A:C', 18)\n",
    "worksheet.set_column('D:D', 32)\n",
    "worksheet.set_column('E:E', 16)\n",
    "worksheet.set_column('F:F', 18, format3)\n",
    "worksheet.set_column('G:H', 16, format2)\n",
    "worksheet.set_column('I:I', 18, format4)\n",
    "worksheet.set_column('J:L', 18, format1)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa13a39-738c-48b8-920b-3578be3f5232",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "historical_data_id = \"1pzlQEQE4FI4OnGrhKMfu1Skwrvs-FubYuEn-Ez5HpsM\"\n",
    "\n",
    "response = service.spreadsheets().values().clear(\n",
    "    spreadsheetId=historical_data_id,\n",
    "    range=\"Data\",\n",
    "    ).execute()\n",
    "\n",
    "response = service.spreadsheets().values().update(\n",
    "    spreadsheetId=historical_data_id,\n",
    "    valueInputOption='RAW',\n",
    "    range=\"Data!A1\",\n",
    "    body=dict(\n",
    "        majorDimension='ROWS',\n",
    "        values=data.fillna(value = 0).T.reset_index().T.values.tolist())\n",
    ").execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5c2ddb-11ed-479f-a5e7-75ad8aabba9b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "response = service.spreadsheets().values().clear(\n",
    "    spreadsheetId=historical_data_id,\n",
    "    range=\"Pivot_Data\",\n",
    "    ).execute()\n",
    "\n",
    "response = service.spreadsheets().values().update(\n",
    "    spreadsheetId=historical_data_id,\n",
    "    valueInputOption='RAW',\n",
    "    range=\"Pivot_Data!A1\",\n",
    "    body=dict(\n",
    "        majorDimension='ROWS',\n",
    "        values=pivot_data.fillna(value = \"N/A\").T.reset_index().T.values.tolist())\n",
    ").execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## below code is to copy this freeze waterfall into the archive"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "isFreeze=True\n",
    "if isFreeze:\n",
    "    scope = [\n",
    "    'https://www.googleapis.com/auth/spreadsheets',\n",
    "    'https://www.googleapis.com/auth/drive',\n",
    "    'https://www.googleapis.com/auth/drive.file'\n",
    "    ]\n",
    "\n",
    "    # this is ID for waterfall live, but we just updated it using freeze data\n",
    "    SPREADSHEET_ID = \"1ZkSLZH2QwHnfdSpQUWAv2qum6xzhemngjWQBJBn_KeM\"\n",
    "    #SPREADSHEET_ID = \"1ULOqqkYP7DDhVkZBoEA3i-Ka4x_YBPtAPuIzb84Ekrg\" # GAB LAST TEST\n",
    "    # The file token.json stores the user's access and refresh tokens, and is\n",
    "    # created automatically when the authorization flow completes for the first\n",
    "    # time.\n",
    "    if os.path.exists('drive_file_token.json'):\n",
    "            creds = Credentials.from_authorized_user_file('drive_file_token.json', scope)\n",
    "    '''flow = InstalledAppFlow.from_client_secrets_file('client_secret_510599516312-aj6d72c90n3fmrbf3ou6gromil06pr8c.apps.googleusercontent.com.json', scope)\n",
    "    creds = flow.run_local_server(port=0)\n",
    "    with open('drive_file_token.json', 'w') as token:\n",
    "        token.write(creds.to_json())'''\n",
    "    service = build('drive', 'v3', credentials=creds)\n",
    "\n",
    "    # extract the most recent freeze id from the url provided and get the file name using that id\n",
    "    freeze = pd.read_excel(\"excel_input/freeze_address.xlsx\")\n",
    "    freeze.columns = freeze.iloc[0]\n",
    "    freeze.drop([0], inplace = True)\n",
    "    freeze_address = str(freeze.iloc[-1][\"Freeze URL\"])\n",
    "    #print(freeze_address)\n",
    "    freeze_id = freeze_address.split(\"/\")[5]\n",
    "\n",
    "    #get the file name of most recent freeze sheet, which include the date of the freeze\n",
    "    response = service.files().get(fileId=freeze_id).execute()\n",
    "    freeze_name  =\"Portfolio Waterfall - \" + response[\"name\"]\n",
    "\n",
    "    # after updating the portfolio waterall live, copied it to the archive folder\n",
    "    archive_folder_id = \"13f2xspl16wzdHBRwhgnEkKj80zLL9Rzu\"\n",
    "    newfile = {'name': freeze_name,  'parents' : [archive_folder_id]}\n",
    "    response = service.files().copy(fileId=SPREADSHEET_ID, body=newfile).execute()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "freeze_name"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "link_base = \"https://docs.google.com/spreadsheets/d/\"\n",
    "link = link_base + response['id']\n",
    "date = freeze_last_date\n",
    "link"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scope = [\n",
    "'https://www.googleapis.com/auth/spreadsheets',\n",
    "'https://www.googleapis.com/auth/drive',\n",
    "]\n",
    "# this is ID for testing\n",
    "SPREADSHEET_ID = response['id']\n",
    "if os.path.exists('write_token.json'):\n",
    "        creds = Credentials.from_authorized_user_file('write_token.json', scope)\n",
    "service = build('sheets', 'v4', credentials=creds)\n",
    "response = service.spreadsheets().values().batchUpdate(\n",
    "    spreadsheetId=SPREADSHEET_ID,\n",
    "    body={\n",
    "        \"valueInputOption\":'RAW',\n",
    "        'data':{\n",
    "            'range':\n",
    "            [[1,2]],\n",
    "        'ValueRanges':\n",
    "}).execute()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "freeze_name"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}